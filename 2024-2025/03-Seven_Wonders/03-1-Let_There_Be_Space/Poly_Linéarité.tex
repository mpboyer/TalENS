\documentclass{classe}
\title{Let there be space\\ \small Cours TalENS n°3}
\author{Clément Allard - Matthieu Boyer}
\date{11 janvier 2025}

\usepackage[pdftex,outline]{contour}

\newcommand{\point}[3]{\draw (#1 -.1, #2 -.1) -- (#1 + .1, #2 + .1);
\draw (#1 +.1, #2 -.1) -- (#1 - .1, #2 + .1);
\draw (#1, #2) node[below right]{#3};}

\renewcommand*{\K}{\mathbb{K}}
\graphicspath{{./Images/}}
\tikzset { domaine/.style 2 args={domain=#1:#2} }

\begin{document}

\section{Découvrons la linéarité}

\subsection{Ce qui marche déjà bien}

Commençons avec un exemple simple : la géométrie dans le plan. Mais on va le voir d'un point de vue différent. On va se donner une origine $O$ et on va repérer chaque point par un vecteur : à un point $M$ on associera le vecteur $\overrightarrow{OM}$. Bon dans notre plan qu'est ce qu'on a le droit de faire (par exemple) :

\begin{itemize}
	\item On a le droit d'ajouter deux vecteurs $\vec{u}$ et $\vec{v}$, on obtient un troisième vecteur qui est toujours dans le plan, et on a $\vec{u} + \vec{v} = \vec{v} + \vec{u}$;
	\item Il existe un vecteur qui traduit le non déplacement $\vec{0}$;
	\item À chaque vecteur $\vec{u}$, on peut associer un autre vecteur $\overrightarrow{-u}$ tel que $\vec{u} + \overrightarrow{-u} = \vec{0}$ : on parle d'opposé;
	\item On a le droit de multiplier un vecteur par un nombre (on parle de multiplication par un scalaire), et on obtient que $\overrightarrow{\lambda u} = \lambda \vec{u}$. On rappelle que $-1$ est un nombre et que l'on a $-\vec{u} = \overrightarrow{-u}$;
	\item On a $(\lambda + \mu)\vec{u} = \lambda\vec{u} + \mu\vec{u}$ (distributivité scalaire) et $\lambda(\vec{u}+\vec{v}) = \lambda\vec{u}+\lambda\vec{v}$ (distributivité vectorielle).
\end{itemize}

On peut décomposer les vecteurs sur des vecteurs dits de base, et on peut leur appliquer différentes opérations, comme une projection orthogonale ou bien une rotation selon un axe. Ce formalisme fonctionne très bien pour la géométrie dans le plan, et on peut l'étendre à plein d'autres concepts mathématiques.

\subsection{Explorons l'inexploré !}

\begin{définition}{L'ensemble $\mathbb{R}$}{}
On note $\mathbb{R}$ l'ensemble des nombres réels.
\end{définition}

\begin{définition}{Groupes}{}
Soit $G$ un ensemble muni d'une loi interne $\star$, le couple $(G,\star)$ est une structure de {\bf groupe}
 (plus simplement un groupe) si, et seulement si~:
\par\hskip1cm - $\star$ est associative
\par\hskip1cm - $\star$ admet un \'{e}l\'{e}ment neutre $e$
\par\hskip1cm - Chaque \'{e}l\'{e}ment de $G$ admet un \'{e}l\'{e}ment sym\'{e}trique, ie~:
$$\forall x\in G,\quad \exists x'\in G,\quad x\star x'= x'\star x = e\quad (x'=x^{-1})$$
\end{définition}

\begin{définition}{Un anneau}{}
Soit $A$ un ensemble muni de deux lois de composition interne $+$ et
$\star$, le triplet $(A,+,\star)$ est une structure d'{\bf anneau}
(plus simplement un anneau) si, et seulement si~:
\par\hskip1cm - $(A,+)$ est un groupe commutatif.
\par\hskip1cm - $\star$ est distributive \`{a} gauche et \`{a} droite par rapport \`{a} $+$.
\end{définition}

\begin{définition}{Un corps}{}
Soit $\K$ un ensemble muni de deux lois $+$ et $\times$, le triplet 
$(\K,+,\times)$ est une structure
de \textbf{corps} (plus simplement un corps) si, et seulement si~:
\par\hskip1cm - $(\K,+,\times)$ est un anneau. 
\par\hskip1cm - $(\K^*,\times)$ est un groupe. $(\K^*=\K\setminus\{0\})$
\end{définition}

\begin{théorème}{$\mathbb{R}$ existe}{}
	L'ensemble $\mathbb{R}$ muni de l'addition $+$ usuelle et de la multiplication usuelle $\times$ est un corps.
\end{théorème}

\begin{définition}{$\mathbb{R}$-Espace Vectoriel}{}
	Soit $E$ un ensemble. Il existe une addition $+$ et un produit extérieur $\cdot$ tels que
	\begin{itemize}
		\item On peut faire des additions sur $E$, avec existence d'un élément neutre $0_E$ et d'un opposé (que l'on note $-u$) : on a $u+v = v+u$, $u+(v+w) = (u+v)+w$, $u+0=u$ et $u + (-u) = 0$ pour $u$, $v$ et $w$ trois éléments de $E$.
		\item On peut multiplier des vecteurs par des scalaires avec le produit extérieur : $\lambda\cdot x$ est encore un élément de $E$ pour $\lambda \in \mathbb{R}$.
		\item La multiplication se comporte bien avec l'addition : on peut distribuer des scalaires et des vecteurs, multiplier par $1$ un vecteur ne le change pas : on a $(\lambda + \mu)\cdot u = \lambda\cdot u + \mu\cdot u$ (distributivité scalaire) et $\lambda\cdot (u+v) = \lambda \cdot u+\lambda\cdot v$ (distributivité vectorielle), $1\cdot u = u$, $(\lambda\times\mu)\cdot u = \lambda\cdot (\mu\cdot u)$ pour $u$, et $v$ éléments de $E$ et $\lambda$ et $\mu$ des réels.
	\end{itemize}
	Alors $E$ est un $\mathbb{R}$-espace vectoriel.
\end{définition}

\begin{définition}{Vecteurs et scalaires}{}
	Les éléments de $E$ sont appelés vecteurs et ceux de $\mathbb{R}$ des scalaires.
\end{définition}

\begin{définition}{$\mathbb{R}$-Espace Vectoriel : ce qu'il faut en retenir}{}
	Soit $E$ un ensemble. Il existe une addition $+$ et un produit extérieur $\cdot$ tels que
	\begin{itemize}
		\item On peut faire des additions sur $E$, avec existence d'un élément neutre $0_E$ tel que $x + 0_E = 0_E + x = x$ pour $x$ dans $E$, et d'un opposé.
		\item On peut multiplier des vecteurs par des scalaires avec le produit extérieur : $\lambda\cdot x$ est encore un élément de $E$ pour $\lambda \in \mathbb{R}$.
		\item La multiplication se comporte bien avec l'addition : la multiplication et le produit extérieur se distribuent sur l'addition.
	\end{itemize}
	Alors $E$ est un $\mathbb{R}$-espace vectoriel.
\end{définition}

\begin{remarque}{Et sur d'autres corps ?}{}
On peut définir également des espaces vectoriels sur d'autres corps en remplaçant $\mathbb{R}$ par un autre corps dans les définitions.
\end{remarque}

\subsection{Revenons sur $\mathbb{R}^2$}

Essayons de montrer que $\mathbb{R}^2$ (appelé précédemment "Géométrie euclidienne dans le plan") est un $\mathbb{R}$-espace vectoriel. On note les éléments de $\mathbb{R}^2$ sous la forme suivante : $(x, y)$ où $x\in\mathbb{R}$ et $y\in\mathbb{R}$.

\begin{enumerate}
	\item En revenant à l'intuition géométrique du début (les points sont assimilés à des vecteurs par rapport à l'origine), quelles seraient les opérations d'addition et de produit extérieur que l'on pourrait prendre ?
	\item Vérifions que ces opérations sont compatibles pour montrer que $\mathbb{R}^2$ avec ces opérations est un espace vectoriel.
\end{enumerate}

\subsection{Autres exemples d'espaces vectoriels}

\subsubsection{$\mathbb{R}^n$}

\begin{définition}{Espace/Espace-Temps}{}
On peut définir de même ce qu'on appelle "espace" en géométrie euclidienne : $\mathbb{R}^3$ dont les vecteurs s'écrivent sous la forme $(x, y, z)$, et aller plus loin avec par exemple l'espace-temps en géométrie euclidienne $\mathbb{R}^4$ de vecteurs $(x, y, z, t)$ etc. On garde les mêmes lois que pour $\mathbb{R}^2$ : on a $(x, y, z) + (x', y', z') = (x+x', y+y', z+z')$ et $\lambda(x, y, z) = (\lambda x, \lambda y, \lambda z)$
\end{définition}

\subsubsection{Les fonctions réelles}

\begin{définition}{Fonction réelle à valeurs réelles}{}
On appelle fonction réelle à valeurs réelles toute fonction qui a un réel associe un autre réel.
\end{définition}

\begin{théorème}{Espace vectoriel des fonctions réelles à valeurs réelles}{}
On définit $f+g$ pour $f$ et $g$ des fonctions à valeurs réelles par la relation $(f+g)(x) = f(x)+g(x)$ et $\lambda f$ par $(\lambda f)(x) = \lambda f(x)$. On obtient que l'ensemble des fonctions réelles muni des deux opérations est un $\mathbb{R}$-espace vectoriel.
\end{théorème}

\subsection{Sous-espace vectoriel}

\begin{définition}{Sous-espace vectoriel}{}
	On dit que $F$ est un sous-espace vectoriel de $E$ si et seulement si $0_E$ appartient à $F$ et que $F$ est stable par toute combinaison linéaire : pour tous $\lambda$, $\mu \in \mathbb{R}$ et $x$, $y\in F$, $\lambda x + \mu y \in F$.
\end{définition}

\begin{example}{}
	Par exemple, une droite passant par l'origine est un sous-espace vectoriel de $\mathbb{R}^2$.
\end{example}

\begin{définition}{Combinaison linéaire}{}
On appelle combinaison linéaire d'éléments de $A$ tout vecteur $x$ pouvant s'écrire sous la forme $x = \lambda_1 x_1 + \lambda_2 x_2 + \cdots + \lambda_p x_p$ pour $p$ un entier, $\lambda_1 \cdots \lambda_p$ des scalaires et $x_1 \cdots x_p$ des vecteurs.
\end{définition}

\begin{définition}{Espace vectoriel engendré par des vecteurs}{}
On note $\mathrm{Vect}(A)$ l'espace vectoriel engendré par un ensemble de vecteurs $A$, c'est à dire :
\begin{itemize}
\item Le plus petit espace vectoriel contenant chaque vecteur de $A$.
\item Le sous espace vectoriel de $E$ contenant toute combinaison linéaire d'éléments de $A$.
\end{itemize}
\end{définition}

\section{Liberté, bases et dimension}

\begin{définition}{Famille}{}
On appelle famille $(x_i)$ un ensemble ordonné d'éléments : on se donne $I$ un ensemble et pour tout élément de $i$ de $I$, on associe un élément $x_i$.
\end{définition}

\begin{définition}{Famille libre, génératrice, base}{}
\begin{itemize}
\item Une famille est dite libre si, pour toute famille de scalaires $(\lambda_i)$ indexée par $I$, la condition $\sum_{i\in I} \lambda_i x_i = 0$ donne que tous les $\lambda_i$ sont nuls;
\item Une famille est dite génératrice si, pour tout élément de $E$, on peut associer une écriture sous la forme $\sum_{i\in I} \lambda_i x_i$;
\item Une famille est une base si elle est libre et génératrice. Ceci est équivalent au fait qu'il existe, pour chaque élément de $E$ une unique écriture sous la forme $\sum_{i\in I} \lambda_i x_i$.
\end{itemize}
\end{définition}

\begin{example}
Dans $\mathbb{R}^2$, $((1, 0),(0, 1))$ forme une base de $\mathbb{R}^2$ : en effet, tout vecteur $(a, b)$ peut s'écrire sous la forme $a(1, 0) + b(0, 1)$ et si $(0, 0) = a(1, 0) + b(0, 1) = (a, b)$, alors on a nécessairement $a=b=0$
\end{example}

\begin{remarque}{Comment retenir "avec les mains"}{}
A chaque vecteur de la famille, on associe un "axe" qui est l'ensemble des déplacements que l'on peut faire selon cet "axe" (en allant dans la direction du vecteur).
\begin{itemize}
	\item La liberté s'illustre comme le fait que chacun de nos axes est utile : un déplacement selon cet axe ne pourrait être substitué en se déplaceant selon d'autre axes;
	\item Le caractère générateur s'illustre comme le fait qu'on puisse atteindre un point en se déplaceant selon nos axes;
	\item Si notre famille est une base, alors on a, pour tout point, une seule combinaison de vecteurs permettant d'atteindre ce point.
\end{itemize}
\end{remarque}

\begin{définition}{Dimension}{}
En se donnant une base d'un espace vectoriel, on appelle dimension la taille de la base : ceci correspond au nombre d'indices. La dimension ne dépend pas de la base choisie.
\end{définition}

%TODO : preuve

\section{Applications linéaires et matrices}

Maintenant que nous avons introduit les notions de vecteurs et de bases, essayons de voir comment modéliser des transformations : une dilatation, projection orthogonale ou bien rotation selon un axe. Le formalisme pertinent est celui d'application linéaire.

\begin{définition}{Application linéaire}{}
On considère deux espaces vectoriels $E$ et $F$. On appelle application linéaire une fonction $f$ qui à un élément de $E$ associe un élément de $F$, et qui vérifie les propriétés suivantes :
\begin{itemize}
	\item Pour tous vecteurs $x$ et $y$ de $E$, $f(x+y) = f(x)+f(y)$
	\item Pour tout vecteur $x$ de E et tout scalaire $\lambda$, $f(\lambda x) = \lambda f(x)$
\end{itemize}
\end{définition}

\begin{propositionfr}{Opérations avec des applications linéaires}{}
On a 
$$f(\lambda_1 x_1 + \cdots + \lambda_n x_n) = \lambda_1 f(x_1) + \cdots + \lambda_n f(x_n)$$
où $\lambda_1 \cdots \lambda_n$ sont des scalaires et $x_1 \cdots x_n$ des vecteurs.
\end{propositionfr}

\begin{théorème}{Identification d'applications linéaires}{}
Soient $E$ et $F$ deux espaces vectoriels, $(e_i)_{i\in I}$ une base de $E$ et $(y_i)_{i\in I}$ une famille de vecteurs de $F$. Il existe une unique application linéaire telle que, pour tout indice $i$, $f(e_i) = y_i$.
\end{théorème}

\begin{remarque}{Utilité}{}
Ce théorème est essentiel car il permet de comprendre les applications linéaires en s'intéressant uniquement à l'image d'une base, car par linéarité on peut trouver la valeur de \textbf{n'importe quel} vecteur.
\end{remarque}

Donnons nous un exemple pour visualiser ceci : on considère $\mathbb{R}^3$ comme espace vectoriel de départ et d'arrivée : on prend $E = F = \mathbb{R}^3$. Comment peut-on décrire la rotation d'un d'angle $\pi$ autour de l'axe $z$ ? On utilise notre théorème précédent : on sait que $f(x) = -x$, $f(y) = -y$ ainsi que $f(z) = z$. Ensuite, on utilise notre théorème précédent : pour tout vecteur $u$, on a l'existence de scalaires tels que $u = \alpha x + \beta y + \gamma z$, et donc $f(u) = \alpha f(x) + \beta f(y) + \gamma f(z)$ ce qui donne donc $f(u) = -\alpha x - \beta y + \gamma z$

%TODO : figure sympa pour illustrer la rotation

\section{Exemple des équations différentielles linéaires}

\begin{définition}{Équation différentielle linéaire d'ordre 1}{}
On appelle une équation linéaire d'ordre 1 toute équation de la forme
$$y' + a(x)y = b(x)$$ 
où l'inconnue $y$ est une fonction dérivable sur $I$ ($I$ un intervalle), $a$ et $b$ sont des fonctions continues sur $I$.
\end{définition}

Ce type d'équations est très présent que ce soit en physique ou bien dans d'autres domaines des sciences. Mais on peut se demander : comment les résoudre ? On va se placer à présent dans le cas où $b=0$. On cherche donc à résoudre 
$$y' + a(x)y = 0$$.

On peut remarquer quelque chose : l'ensemble des solutions $S$ est un sous espace vectoriel de l'ensemble des fonctions réelles à valeurs réelles !

Mais donc comment trouver une solution ? On considère une fonction $f$ sous la forme $f(x) = g(x)\mathrm{e}^{h(x)}$. On a $f$ dérivable avec $f'(x) = g'(x)\mathrm{e}^{h(x)} + g(x)h'(x)\mathrm{e}^{h(x)} = (g'(x) + g(x)h'(x))\mathrm{e}^{h(x)}$.

Ici on peut voir que notre équation différentielle y ressemble en prenant $y = g$ et $h' = a$. On observe donc que
$$f'(x) = (y'(x) + a(x)y(x))\mathrm{e}^{h(x)} = 0$$
d'où 
$$f(x) = \lambda$$
où $\lambda$ est une constante : on a donc $y(x) = \lambda\mathrm{e}^{-h(x)}$
\\\\
On obtient donc que $S = \mathrm{Vect}(\mathrm{e}^{-h(x)})$ et que donc $S$ est de dimension 1 : c'est une droite !

\end{document}