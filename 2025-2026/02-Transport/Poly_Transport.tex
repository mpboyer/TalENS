\documentclass[info, math]{mpb-cours}

\title{Transport Optimal et Architecture}
\author{Matthieu Boyer}
\date{Cours TalENS 2 2025-2026}

\def\X{\mathcal{X}}
\def\Y{\mathcal{Y}}

\begin{document}
\bettertitle

Ce polycopié ne doit pas être vu comme un remplacement au cours, mais simplement comme un résumé du contenu qui permet d'être sûr de ne rien manquer.

\section{Problème de Monge}
Gaspard Monge, ingénieur militaire de Napoléon, est chargé par ce dernier du problème suivant:
\begin{center}
	Étant donné des grognards portant des sacs de sable depuis $n$ camps, quelle est la manière optimale de
	construire $n$ murs à des endroits différents, sachant que les endroits sont à des distances plus ou
	moins grandes de chaque camp~?
\end{center}
Ce problème fait partie de la grande classe des problèmes d'optimisation, et est fondamental en théorie des
probabilités, puisqu'il est à la base de la théorie du transport optimal qui donne des manières de trouver
des distributions de probabilités "moyennes".

\subsection{Bases de Probabilités}
On ne rentrera pas ici dans les "vraies" bases de la théorie de la mesure, et notamment sur la notion de tribu.

\begin{definition}
	Une mesure sur un espace $\X$ muni d'une tribu ensemble $\Sigma$ de parties de $X$ est une application
	$\mu: \Sigma \to \R$ telle que:
	\begin{itemize}
		\item $\mu(\emptyset) = 0$
		\item $\mu(A \cup B) = \mu(A) + \mu(B) - \mu(A \cap B)$
		\item $\mu\left(\bigcup_{i = 0}^{\infty} A_{i}\right) = \sum_{i = 0}^{\infty} \mu(A_{i})$ si les $A_{i}$ sont deux
		      à deux disjoints
		\item $A \subseteq B \Rightarrow \mu(A) \leq \mu(B)$.
	\end{itemize}
	On dit que $\mu(\X)$ est la masse totale de $\mu$.
\end{definition}
Intuitivement, une mesure est une application qui donne la quantité d'éléments dans une partie d'un espace.

Dans notre cas, on s'intéressera principalement aux cas $\abs{\X} \hookrightarrow \N$ et $X = \R^{d}$.
\begin{definition}
	Sur $\X$ au plus dénombrable, on a une mesure dite de comptage qui a chaque partie de $X$ associe son nombre d'éléments.

	Sur $\X = \R^{d}$ on a une mesure $\lambda$ dite mesure de Lebesgue qui à chaque partie de $X$ associe son volume.
	En particulier, $\lambda\left(\prod_{i} \left[a_{i}, b_{i}\right]\right) = \prod_{i} \abs{b_{i} - a_{i}}$.
\end{definition}

\begin{definition}
	Une mesure de probabilité est une mesure positive de masse $1$.
	Une mesure $\mu$ a densité par rapport à la mesure de Lebesgue s'il existe une fonction $p$ telle que
	\begin{equation*}
		\mu(A) = \int_{A} p(x)\d\lambda(x)
	\end{equation*}
\end{definition}
Le symbole intégrale $\int$ signifie ici que pour tout point $x$ dans $A$, on construit un petit pavé autour
de $A$, qu'on calcule son volume $\d\lambda(x)$ et qu'on le multiplie par la densité de $\mu$ en $x$ $p(x)$.

Autrement dit, dans le volume $\d\lambda(x)$ autour de $x$, il y a $p(x)$ particules. On trouve donc le
nombre total de particules dans $A$ en sommant les nombres de particules autour de tout point $x$ de $A$.

\begin{definition}
	Pour $x \in \R^{d}$, on définit le dirac en $x$ comme la mesure de probabilité $\delta_{x}$ qui vaut $1$ sur $\{x\}$ et $0$ ailleurs.

	Pour $\mu \in \R^{d}, \Sigma \in \M_{d, d}(\R)$, on définit la gaussienne centrée en $\mu$ de covariance
	$\Sigma$ par sa densité $p(x) = \exp\left(-\frac{1}{2}\Sigma^{-1}\left(x - \mu\right)^{2}\right)$.
\end{definition}

\begin{definition}
	Une variable aléatoire $X$ à valeurs dans $E$ est une fonction dite mesurable de $\X$ dans $E$.
	La probabilité que $X$ soit à valeurs dans $A \subseteq E$ est la mesure $\mu(X^{-1}(A))$.
\end{definition}

Autrement dit, c'est la quantité (au sens de $\mu$) d'antécédents des éléments de $A$ dans par $X$.

\subsection{Formulation de Monge}
On considère dans la suite deux mesures de probabilité $\alpha \in \mP(\X), \beta \in \mP(\Y)$.
\begin{definition}
	Pour $T: \X \to \Y$, on définit la mesure $T_{\sharp}\alpha$ par $T_{\sharp}\alpha(B) = \alpha(T^{-1}(B))$.
\end{definition}
Autrement dit, $T_{\sharp}\alpha(B)$ est la quantité (selon $\alpha$) d'antécédents des éléments de $B$ par
$T$.

\smallskip

La formulation de Monge du problème de transport optimal de $\alpha$ à $\beta$ est la suivante:
\begin{definition}
	Soit $c$ une fonction de coût de $\X$ à $\Y$, c'est-à-dire une fonction positive de $\X$ dans $\Y$.
	Le problème de Monge associé à $\alpha, \beta, c$ est de calculer:
	\begin{equation}
		M = \inf_{T: \X \to \Y} \left\{\int c(x, T(x))\d\alpha(x) \suchthat T_{\sharp}\alpha = \beta\right\}
	\end{equation}
\end{definition}
$M$ représente la manière optimale de déplacer tout le poids de $\alpha$ vers $\beta$, sachant le coût du
déplacement d'un point de $\X$ vers un point de $\Y$.

\begin{definition}
	Pour $c = \norm{\cdot}$ une norme, on définit la $p$-distance de Wasserstein associée à $c$ comme
	\begin{equation*}
		W_{p}(\alpha, \beta) = \inf_{T_{\sharp}\alpha = \beta}\sqrt[p]{\int \norm{x - T(x)}^{p}\d \alpha(x)}.
	\end{equation*}
\end{definition}

\section{Calcul et Applications}
\subsection{Calcul Discret}
Dans le cas, plus simple, où $\alpha = \sum_{i = 1}^{N} a_{i}\delta_{x_{i}}$ et
$\beta = \sum_{j = 1}^{N} b_{j}\delta_{y_{j}}$, les applications $T$ telles que $T_{\sharp}\alpha = \beta$
correspondent à des assignations des $x_{i}$ aux $y_{j}$, c'est à dire une permutation $\sigma$ de
l'ensemble $\onen{N}$ telle que $T(x_{i}) = y_{\sigma(i)}$.

Le problème d'optimisation qui correspond au transport optimal dans ce cas est le problème de couplage
sur un graphe biparti complet:

\begin{definition}
	Un graphe biparti complet est constitué d'un ensemble $V = A \sqcup B$ de \emph{sommets} composé de deux
	parties $A$ et $B$ de tailles égales $n$.
	Pour chaque sommet de $A$ on ajoute une \emph{arête} à tout sommet de $B$ avec des poids associés
	au coût entre les	deux sommets.
	Un couplage sur un graphe biparti est le choix de $n$ arêtes qui touchent tout sommet de $A$ et tout
	sommet de $B$.
\end{definition}

Dans l'Algorithme \ref{alg:hung} on présente un pseudo-code pour l'algorithme hongrois qui permet de
résoudre ce problème.
L'idée de base étant de se ramener à chaque itération à un problème plus simple: une fois qu'un sommet est
assigné, on le "supprime" virtuellement de la matrice de coût puis on recommence jusqu'à avoir terminé.
Cet algorithme est dit \emph{glouton} parce qu'il effectue à tout instant l'assignation la plus efficace.

Cet algorithme est assez efficace, pusiqu'il effectue un nombre d'opérations dit $\O(n^{3})$
(lire \og grand O de $n^{3}$ \fg), qui est de l'ordre de $n^{3}$ et plus mathématiquement, il existe une
constante positive $C$ telle que le nombre d'opérations $f(n)$ en fonction de $n$ vérifie $f(n) \leq n^{3}$.

\begin{algorithm}
	\caption{Algorithme Hongrois pour le problème d'assignation bipartite}
	\label{alg:hung}
	\begin{algorithmic}
		\Procedure{MaxZ}{$C$} \Comment{Input: Cost matrix $C$ of size $t \times t$}
		\State $Z \gets \{\}$
		\While{$0 \in C_{i,j}$, $\forall(i,j) \notin Z$}
		\State $x \gets$ row such that $C_{x,y}$ has the fewest marked $0$ elements
		\State $y \gets$ column such that $C_{x,y} = 0$ and $C_{y}$ has the fewest marked $0$ elements
		\State Add $(x,y)$ to set $Z$
		\State Mark $C_{x,y}$ as an independent zero
		\EndWhile
		\Statex
		\Return{Set $Z$ containing independent zeros}
		\EndProcedure
		\Statex
		\Procedure{MinCover}{$C, Z$} \Comment{Input: Cost matrix $C$ and set $Z$}
		\State $coveredRows \gets \{\}$ \Comment{Rows covered with horizontal lines}
		\State $coveredCols \gets \{\}$ \Comment{Columns covered with vertical lines}
		\While{$C_{i,j} = 0$ and $i \notin coveredRows$}
		\If{$0 \in C_i$ and $i \in Z$}
		\State $coveredRows \gets i$ \Comment{Cover row $i$}
		\EndIf
		\If{$C_{i,j} = 0$ and $i \notin coveredRows$}
		\State $coveredCols \gets j$ \Comment{Cover column $j$}
		\EndIf
		\EndWhile
		\Statex
		\Return{$coveredRows, coveredCols$}
		\EndProcedure
		\Statex
		\Procedure{Hungarian}{$C$} \Comment{Input: Cost matrix $C$ of size $t \times t$}
		\For{every row $i$ and column $j$ in $C$}
		\State $C_i \gets C_i - \min(C_i)$ \Comment{Subtract row minimum}
		\State $C_j \gets C_j - \min(C_j)$ \Comment{Subtract column minimum}
		\EndFor
		\State $Z \gets$ \Call{MaxZ}{$C$}
		\State $cx, cy \gets$ \Call{MinCover}{$C, Z$}
		\While{$\text{len}(cx) + \text{len}(cy) < n$}
		\State $minVal \gets \min(C_{ij})$ such that $i \notin cx$ and $j \notin cy$
		\For{every row $i \notin cx$ and column $j \notin cy$}
		\State $C_{ij} \gets C_{ij} - minVal$
		\EndFor
		\State $Z \gets$ \Call{MaxZ}{$C$}
		\State $cx, cy \gets$ \Call{MinCover}{$C, Z$}
		\EndWhile
		\Statex
		\Return{Set $Z$ containing index $(i, j)$ of assignments}
		\EndProcedure
	\end{algorithmic}
\end{algorithm}

\subsection{Applications du Transport Optimal}


\end{document}
